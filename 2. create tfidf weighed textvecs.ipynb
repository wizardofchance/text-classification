{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>adj_listO_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have bought several the vitality canned dog fo...</td>\n",
       "      <td>[good, stew, look, product, like, quality]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts t...</td>\n",
       "      <td>[unsalted, sized, sure]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this confection that has been around few centu...</td>\n",
       "      <td>[recommend, chewy, heaven, highly, yummy, mout...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you are looking for the secret ingredient robi...</td>\n",
       "      <td>[good, medicinal, soda, flavor]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price there was wide assortm...</td>\n",
       "      <td>[price, assortment, yummy, delivery, great, ta...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  have bought several the vitality canned dog fo...   \n",
       "1  product arrived labeled jumbo salted peanuts t...   \n",
       "2  this confection that has been around few centu...   \n",
       "3  you are looking for the secret ingredient robi...   \n",
       "4  great taffy great price there was wide assortm...   \n",
       "\n",
       "                                     adj_listO_words     score  \n",
       "0         [good, stew, look, product, like, quality]  positive  \n",
       "1                            [unsalted, sized, sure]  negative  \n",
       "2  [recommend, chewy, heaven, highly, yummy, mout...  positive  \n",
       "3                    [good, medicinal, soda, flavor]  negative  \n",
       "4  [price, assortment, yummy, delivery, great, ta...  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedText = pd.read_csv('df_amazon.csv').cleanedText\n",
    "adj_listO_words = np.load('df_adjective_listO_words.npy')\n",
    "adj_text = pd.read_csv('df_adjective_text.csv').text\n",
    "score = pd.read_csv('df_adjective_text.csv').score\n",
    "\n",
    "df_amazon_adj = pd.DataFrame().assign(text = cleanedText, \n",
    "                                      adj_listO_words = adj_listO_words,\n",
    "                                      score = score)\n",
    "df_amazon_adj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fn1: RETURNS LIST OF TFIDF WEIGHED SENTENCE VECTORS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrn3_listO_tf_w2v_textVec(corpus, w2vmodel, w2v_dims, tfidf_feat, matO_tfidf):\n",
    "    \n",
    "    from progressbar import ProgressBar\n",
    "    pbar1 = ProgressBar()\n",
    "    \n",
    "    if str(type(tfidf_feat)) != \"<class 'list'>\":\n",
    "        print('tfidf_feat must be a list')\n",
    "        return\n",
    "    \n",
    "    listO_tf_w2v_textVec = []\n",
    "    listO_anamolous_indices1 = []\n",
    "    listO_anamolous_indices2 = []\n",
    "\n",
    "    row = 0\n",
    "    \n",
    "    for listO_words in pbar1(corpus): \n",
    "        tf_w2v_textVec = np.zeros(w2v_dims) \n",
    "        sumO_tf_idf_vals = 0\n",
    "        for word in set(listO_words): \n",
    "            word = word.lower()\n",
    "            try:\n",
    "                col = tfidf_feat.index(word)\n",
    "                tf_idf_val = matO_tfidf[row, col]                \n",
    "                wordVec = w2vmodel[word]\n",
    "                tf_w2v_textVec += (wordVec * tf_idf_val)\n",
    "                sumO_tf_idf_vals += tf_idf_val\n",
    "            except:\n",
    "                listO_anamolous_indices1.append((row, word))\n",
    "                pass\n",
    "            \n",
    "        condition = (sumO_tf_idf_vals != 0) or sumO_tf_idf_vals\n",
    "        \n",
    "        if condition:\n",
    "            tf_w2v_textVec = tf_w2v_textVec/sumO_tf_idf_vals             \n",
    "        else:\n",
    "            tf_w2v_textVec = np.zeros(w2v_dims)\n",
    "            listO_anamolous_indices2.append(row)\n",
    "            \n",
    "        listO_tf_w2v_textVec.append(tf_w2v_textVec)\n",
    "        row += 1\n",
    "    \n",
    "    print('3 vals returned: listO_tf_w2v_textVec, listO_anamolous_indices1, listO_anamolous_indices2')\n",
    "    return listO_tf_w2v_textVec, listO_anamolous_indices1, listO_anamolous_indices2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW & TFIDF VECTORIZERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_amazon_adj.text\n",
    "\n",
    "BOW = CountVectorizer(stop_words='english', min_df=5)\n",
    "matO_bow = BOW.fit_transform(text)\n",
    "\n",
    "TFIDF = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "matO_tfidf = TFIDF.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((364119, 31304), (364119, 31304))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matO_bow.shape, matO_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31304"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feat = TFIDF.get_feature_names()\n",
    "len(tfidf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('matO_bow.npz', matO_bow)\n",
    "scipy.sparse.save_npz('matO_tfidf.npz', matO_tfidf)\n",
    "np.save('tfidf_feat', tfidf_feat, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING SENTENCE VECTORS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_google = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "matO_bow = scipy.sparse.load_npz('matO_bow.npz')\n",
    "matO_tfidf = scipy.sparse.load_npz('matO_tfidf.npz')\n",
    "tfidf_feat = np.load('tfidf_feat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_dims = w2v_google['wizard'].shape[0]\n",
    "w2v_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (364119 of 364119) |################| Elapsed Time: 0:16:54 Time:  0:16:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 vals returned: listO_tf_w2v_textVec, listO_anamolous_indices1, listO_anamolous_indices2\n"
     ]
    }
   ],
   "source": [
    "corpus = df_amazon_adj.adj_listO_words.values\n",
    "w2vmodel = w2v_google\n",
    "tfidf_feat = list(tfidf_feat)\n",
    "\n",
    "tup3 = retrn3_listO_tf_w2v_textVec(corpus, w2vmodel, w2v_dims, tfidf_feat, matO_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.92878162e-02,  1.44347557e-01,  6.89371794e-02,  7.15543422e-02,\n",
       "       -1.22727715e-02,  7.16988656e-02,  1.18965220e-01, -1.15484713e-01,\n",
       "       -2.74176593e-02,  1.77681201e-01, -1.48702960e-01, -1.97969874e-01,\n",
       "        7.52617787e-02, -1.63147496e-02, -2.13378979e-01,  8.58427428e-02,\n",
       "        8.68626852e-02,  1.10201271e-01, -2.52078722e-02, -1.81099368e-01,\n",
       "       -1.69754713e-02,  9.43785707e-02, -2.97007108e-02,  4.62577035e-02,\n",
       "        4.70311383e-02, -4.42980394e-03, -1.45439970e-02,  5.62720509e-02,\n",
       "       -1.24489483e-01,  5.33022844e-02, -8.67931220e-02,  5.13981029e-02,\n",
       "        6.01518780e-02, -5.10699976e-02,  5.04220448e-02,  3.26314173e-03,\n",
       "        1.26959211e-01, -1.62630385e-01,  1.03982101e-01,  9.96132148e-02,\n",
       "       -1.73088230e-02, -1.66139614e-01,  1.29420982e-01, -1.19608596e-02,\n",
       "       -1.27959048e-01, -2.20956358e-01, -1.18479665e-01,  1.07637609e-01,\n",
       "        6.67668975e-02,  2.21604317e-03, -3.16172800e-02,  8.18147003e-02,\n",
       "       -1.27128060e-01, -8.28835698e-02,  1.92079414e-02, -6.10080897e-02,\n",
       "        9.71863841e-02, -8.87711631e-02,  1.25733213e-01, -1.50798503e-01,\n",
       "        2.04372753e-02,  1.19409754e-01, -1.81609512e-01,  6.86029616e-02,\n",
       "       -1.81952005e-02, -5.39571570e-02, -2.45299168e-02, -7.90571434e-02,\n",
       "       -4.97024975e-02, -1.75202086e-03,  9.02436276e-02, -7.10559641e-02,\n",
       "        5.35395993e-02, -4.84752896e-02, -5.85451249e-02, -6.60141236e-02,\n",
       "       -8.37917591e-02, -2.25491674e-02,  8.44384319e-02,  4.83199465e-02,\n",
       "        6.87579211e-02, -4.20794314e-02,  2.91325305e-02,  4.51823832e-02,\n",
       "       -2.78592043e-02, -8.12652619e-02, -1.38295265e-01,  1.40209301e-01,\n",
       "        6.12716282e-02,  5.38656843e-02,  5.98455921e-02,  2.65580882e-02,\n",
       "       -1.01745822e-01,  1.93760348e-02, -2.53417552e-02, -7.97831690e-02,\n",
       "       -2.18570814e-02,  6.14370819e-02,  1.35658972e-03, -3.04611198e-03,\n",
       "        4.11489765e-02,  1.21041012e-01, -2.47822438e-02, -4.18040928e-02,\n",
       "       -5.17411504e-02, -2.05823891e-01,  6.20805126e-02,  8.23071724e-02,\n",
       "        1.05471064e-01, -2.84899913e-02, -5.20284854e-02,  4.87760969e-02,\n",
       "       -6.58664979e-03, -3.70435916e-02,  2.10319471e-02, -5.84513388e-02,\n",
       "       -1.11153028e-01, -3.23550332e-02, -2.98591409e-02, -4.55073339e-02,\n",
       "       -1.53175296e-01, -7.17010354e-02, -1.94687442e-02,  5.35373747e-02,\n",
       "        4.03806668e-02,  1.71974255e-02, -2.23501251e-01, -4.00524283e-02,\n",
       "       -1.99232100e-02, -3.80080121e-02, -1.22974193e-01,  2.08232080e-01,\n",
       "       -7.36357962e-02,  9.92447264e-02, -9.40855314e-02, -1.40752294e-03,\n",
       "        1.57764906e-01, -2.46633880e-02,  1.32804657e-01,  1.88133375e-02,\n",
       "       -1.86850008e-02,  6.62207021e-03, -3.32692530e-02, -4.19514593e-02,\n",
       "        1.06096170e-01, -1.31652752e-01,  5.12506468e-02,  2.16575451e-02,\n",
       "       -9.11419513e-02,  3.48174576e-02,  5.82340599e-02,  4.85809348e-03,\n",
       "       -1.70623723e-01,  1.30792882e-01, -1.27867195e-01, -1.46154191e-01,\n",
       "       -1.22683286e-01,  2.64286686e-03, -2.33321320e-01, -9.85736223e-02,\n",
       "       -8.58292910e-02, -3.80085560e-02, -1.76037041e-02,  1.03481559e-01,\n",
       "        1.34050271e-01, -7.51520728e-03,  2.61307092e-02, -9.10696492e-02,\n",
       "        1.16263999e-01,  8.46291738e-03, -1.79190666e-01,  2.63613154e-02,\n",
       "        3.38622728e-02, -1.42787708e-01, -6.17761152e-02, -5.16790342e-03,\n",
       "        6.12816793e-02, -5.27807691e-02, -6.63822315e-02,  3.65722408e-02,\n",
       "       -8.17345033e-02, -2.32674789e-01,  8.60084979e-02,  1.47447657e-02,\n",
       "       -1.07489112e-01, -3.31487349e-02, -2.05510713e-01, -6.34504375e-03,\n",
       "       -5.83307532e-02,  2.81493243e-02, -1.43804225e-02, -5.14429674e-02,\n",
       "       -1.39982053e-02, -3.99643846e-02, -1.24417787e-01,  1.43144260e-01,\n",
       "       -8.49933411e-02,  2.75233563e-02, -1.68559601e-01, -5.99741012e-02,\n",
       "       -7.47369497e-02,  4.34635861e-02, -5.31353083e-02,  1.01265679e-01,\n",
       "       -6.48953289e-02, -9.69208157e-02,  2.33538050e-02, -2.14016436e-02,\n",
       "        6.55383168e-02, -1.07190654e-01, -8.05574084e-02,  5.40254341e-02,\n",
       "       -6.69523880e-02,  9.75679019e-02,  1.20518538e-03,  2.48700155e-02,\n",
       "        1.23365051e-01, -4.02752772e-02, -6.65450984e-02,  6.03437948e-03,\n",
       "        2.11919106e-02,  1.85337116e-02,  6.05007430e-03,  8.44006119e-02,\n",
       "        1.51463938e-01,  6.78347825e-02,  1.59733822e-02,  5.38488390e-02,\n",
       "       -1.87746816e-02,  1.07698955e-01, -1.99953060e-02,  4.44150399e-04,\n",
       "        8.50481915e-02, -3.05378237e-04, -5.98013519e-03, -1.01710911e-01,\n",
       "        5.55881936e-02,  1.67831791e-02,  1.64173020e-02, -5.61446012e-02,\n",
       "        1.45711240e-01,  4.24723675e-02,  8.78711373e-02,  6.67170122e-02,\n",
       "        3.50299858e-02, -4.48973545e-03,  1.20400482e-02,  6.62998417e-02,\n",
       "       -1.82513653e-01, -6.50620844e-04, -8.30032033e-02,  1.17507801e-01,\n",
       "        1.36405153e-01,  2.70512104e-02,  3.93094476e-02, -1.33170851e-01,\n",
       "       -8.69181228e-02, -5.77284350e-02,  1.82983539e-02, -6.34275090e-02,\n",
       "        9.31739487e-02,  1.29194283e-01, -1.28086400e-01,  9.08547668e-02,\n",
       "       -5.24311433e-04,  4.91208754e-02, -2.41963605e-02, -8.98561660e-02,\n",
       "       -1.73803505e-01, -7.26364978e-02, -8.32638942e-03,  8.16816966e-02,\n",
       "        6.89020786e-02, -6.28683441e-02,  2.94892053e-02, -2.72756829e-02,\n",
       "       -3.31067784e-02, -7.70849387e-02, -1.17485685e-01, -2.56911812e-02,\n",
       "        5.71660311e-02, -1.20269539e-01,  1.57340931e-01,  1.09824681e-02,\n",
       "       -7.66091695e-02,  3.64783247e-02,  4.20922325e-02,  8.54106954e-02,\n",
       "       -7.74469681e-02,  1.01200076e-01, -2.16772872e-02,  8.38421601e-02,\n",
       "       -1.96108676e-01,  1.21693074e-01, -2.40975393e-02,  5.29733105e-05,\n",
       "        4.66692925e-02, -1.45708185e-01,  5.05960170e-02,  6.86058607e-02])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listO_tf_w2v_textVec = tup3[0]\n",
    "listO_tf_w2v_textVec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364119"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listO_tf_w2v_textVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listO_tf_w2v_textVec = tup3[0]\n",
    "np.save('listO_tf_w2v_textVec', listO_tf_w2v_textVec, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
